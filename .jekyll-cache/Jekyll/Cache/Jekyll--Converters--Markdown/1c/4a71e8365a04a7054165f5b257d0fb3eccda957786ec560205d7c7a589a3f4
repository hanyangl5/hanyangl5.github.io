I"Î<p>å®éªŒè¦æ±‚</p>

<ul>
  <li>å°†æ‰€ç»™äººè„¸ç…§ç‰‡æ–‡ä»¶å¤¹ä½œä¸ºç­çº§äººè„¸æ•°æ®åº“ï¼Œå…¶ä¸­æ¯äººæœ‰äº”å¼ å›¾ç‰‡ã€‚</li>
  <li>testæ–‡ä»¶ä¸‹å­˜å‚¨çš„æ˜¯ç”¨æ¥è¯†åˆ«æˆ–è®¤è¯çš„ä¸å±äºæ•°æ®åº“ä¸­çš„ç…§ç‰‡ï¼Œæ¯äººæœ‰ä¸€å¼ å›¾ç‰‡ã€‚</li>
  <li>å°†äººè„¸è¯†åˆ«çš„ä»£ç å°è£…æˆä¸€ä¸ªå‡½æ•°ï¼Œå‘½åä¸ºfacial_recognitionï¼Œå…¶è¾“å…¥æ˜¯å½“å‰æµ‹è¯•å›¾ç‰‡çš„è·¯å¾„ï¼Œä¸”å‡½æ•°è¦è¿”å›æœ€ç›¸ä¼¼çš„äººçš„åå­—ã€‚</li>
  <li>å°†äººè„¸è®¤è¯çš„ä»£ç å°è£…æˆä¸€ä¸ªå‡½æ•°ï¼Œå‘½åä¸ºfacial_verificationï¼Œå…¶è¾“å…¥æ˜¯æ•°æ®åº“ä¸­æƒ³è¦æ¯”å¯¹çš„äººè„¸idå’Œå½“å‰çš„æµ‹è¯•å›¾ç‰‡çš„è·¯å¾„ï¼Œä¸”å‡½æ•°è¦æ ¹æ®è®¤è¯çš„ç»“æœï¼Œå³è¿”å›å­—ç¬¦ä¸²â€œTrueâ€æˆ–å­—ç¬¦ä¸²â€œFalseâ€ã€‚</li>
  <li>å®šä¹‰äººååˆ—è¡¨ï¼Œåˆ—è¡¨ä¸­æ¯ä¸ªå…ƒç´ æ˜¯äººåå­—ç¬¦ä¸²ï¼ˆå³ç±»ä¼¼äºâ€å¼ ä¸‰â€, â€œæå››â€ï¼‰ï¼Œåˆ—è¡¨åä¸ºnamesï¼Œè¯„æµ‹ä¸­ç”¨åˆ°çš„idå€¼å³ä¸ºåœ¨namesåˆ—è¡¨ä¸­çš„åºå·ï¼ˆä»0å¼€å§‹ï¼‰ã€‚</li>
  <li>æœ€ç»ˆè€ƒæ ¸ç»“æœæ ‡å‡†æ˜¯è¯†åˆ«çš„å‡†ç¡®ç‡å’Œæ—¶é—´ï¼Œä»¥åŠè®¤è¯çš„å››é¡¹æ ‡å‡†ã€‚</li>
</ul>

<p>å¤§ä½œä¸šçš„åå­—æ˜¯äººè„¸è¯†åˆ«ï¼Œä½†åœ¨é˜…è¯»å®éªŒè¦æ±‚åå¯ä»¥çœ‹å‡ºæ˜¯ä¸€ä¸ªåˆ†ç±»é—®é¢˜</p>

<p>ç¬”è€…é€‰ç”¨resnet50è¿›è¡Œåˆ†ç±»</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>|main.ipynb
|æ•°æ®åº“å›¾ç‰‡
    |name1
        |name1_1.jpg
        |name1_2.jpg
        ...
    |name2
        |name2_1.jpg
        |name2_2.jpg
        ...
    ...
|test
    |name1.jpg
    |name2.jpg
</code></pre></div></div>

<p>é¦–å…ˆå¯¼å…¥æ‰€éœ€è¦çš„åº“ä»¥åŠè¿è¡Œæ‰€éœ€è¦çš„å„é¡¹å‡†å¤‡ï¼š</p>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>import os
import torchvision.models as models
from PIL import Image, ImageDraw
import datetime
from torch.autograd import Variable
import torch
import cv2
import numpy as np
from facenet_pytorch import MTCNN, extract_face
import matplotlib.pyplot as plt
import re
from torchvision import transforms, datasets, models
device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')
</code></pre></div></div>

<p>æ„å»ºdatasetï¼Œå› ä¸ºtrainå’Œtestçš„ç›®å½•ç»“æ„ä¸åŒï¼Œæ‰€ä»¥éœ€è¦æ„å»ºä¸¤ä¸ªdataset</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>class TestDataset(torch.utils.data.Dataset):
    def __init__(self, root, list, transform=None):
        self.labellist = list
        self.root = root
        self.transform = transform

    def __len__(self):
        return 1

    def __getitem__(self, index):
        img_path = self.root
        img = Image.open(self.root).convert('RGB')

        label=re.sub("[A-Za-z0-9\!\%\[\]\, \.\-\_\/]", "", img_path)
        label = self.labellist.index(label)
        
        if self.transform:
            img = self.transform(img)
        return img, label


class TrainDataset(torch.utils.data.Dataset):
    def __init__(self, root, list, transform=None):
        self.labellist = list
        self.root = root
        self.transform = transform

        self.images = []
        for files in os.listdir(self.root):
            for filename in os.listdir(os.path.join(root, files)):
                self.images.append(files+'/'+filename)

    def __len__(self):
        return len(self.images)

    def __getitem__(self, index):
        image_index = self.images[index]
        img_path = os.path.join(self.root, image_index)
        img = Image.open(img_path).convert('RGB')
        label = img_path.split('_')[1]
        label = re.sub("[A-Za-z0-9\!\%\[\]\, \.\-\_]", "", label)
        label = self.labellist.index(label)   mapping
        if self.transform:
            img = self.transform(img)
        return img, label
</code></pre></div></div>

<p>names = get_name_list(â€˜../æ•°æ®åº“å›¾ç‰‡/â€™)</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> transform
data_transform = transforms.Compose([
    transforms.Resize((256, 256)),
    transforms.CenterCrop(224),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                         std=[0.229, 0 .224, 0.225])
])
</code></pre></div></div>
<p>åŠ è½½è®­ç»ƒé›†</p>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code> load train
train_dataset =  TrainDataset(
    root="../æ•°æ®åº“å›¾ç‰‡/",list=names, transform=data_transform)
train_loader = torch.utils.data.DataLoader(
    train_dataset, batch_size=4, shuffle=True)
</code></pre></div></div>

<h5 id="åˆå§‹åŒ–æ¨¡å‹å’Œè®­ç»ƒæ–¹æ³•">åˆå§‹åŒ–æ¨¡å‹å’Œè®­ç»ƒæ–¹æ³•</h5>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>net = models.resnet50().to(device)
criterion = torch.nn.CrossEntropyLoss()  # loss function
optimizer = torch.optim.SGD(
    net.parameters(), lr=0.0001, momentum=0.9)  # sgd
epochs = 25
PATH = 'models/resnet152.pth'
if not os.path.exists(PATH):
    print('start training')
    for epoch in range(epochs):  # loop over the dataset multiple times
        running_loss = 0.0
        train_correct = 0
        train_total = 0
        for i, data in enumerate(train_loader, 0):
            inputs, labels = data
            inputs, labels = Variable(
                inputs.cuda()), Variable(labels.cuda())
            optimizer.zero_grad()
            outputs = net(inputs)
            _, train_predicted = torch.max(outputs.data, 1)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            running_loss += loss.item()
            train_total += labels.size(0)
        print('train %d epoch loss: %.3f  ' % (
            epoch + 1, running_loss / train_total))

    print('Finished Training,model saved to ',PATH)  # finish training

    torch.save(net.state_dict(), PATH)
</code></pre></div></div>

<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>def facial_recognition(path):
    test_dataset = Test1Dataset(root=path, list=names, transform=data_transform)
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)
    with torch.no_grad():
        for i, data in enumerate(test_loader):
            images, labels = data
            images, labels = images.to(device), labels.to(device)
            outputs = net(images)
            _, predicted = torch.max(outputs.data, 1)
    return names[predicted]


def facial_verification(id,path):
    test_dataset = Test1Dataset(root=path, list=names, transform=data_transform)
    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=4, shuffle=False)
    dataiter = iter(test_loader)
    images, labels = dataiter.next()
    images, labels = images.to(device), labels.to(device)
    
    outputs = net(images)
    _, predicted = torch.max(outputs, 1)
    print(id,names[predicted[0]])
    return "True" if predicted[0]==id else "False"

</code></pre></div></div>
<h5 id="æµ‹è¯•">æµ‹è¯•</h5>
<div class="highlighter-rouge"><div class="highlight"><pre class="highlight"><code>net = models.resnet50().to(device)
print('load model')
net.load_state_dict(torch.load(PATH))

starttime = datetime.datetime.now()
right = 0
wrong = 0

for item in os.listdir("../test"):

    test_path = "../test/" + item
    if facial_recognition(test_path) == item.split('.')[0]:
        right += 1
    else:
        wrong += 1

accuracy = right / (right+wrong)
endtime = datetime.datetime.now()

print("äººè„¸è¯†åˆ«çš„è€ƒå¯Ÿç»“æœï¼š")
print("äººè„¸è¯†åˆ«çš„å‡†ç¡®ç‡æ˜¯:", accuracy)
print("æ•´ä¸ªäººè„¸è¯†åˆ«çš„è¿è¡Œæ—¶é—´æ˜¯ï¼š", (endtime-starttime).seconds, "s")

tp = 0
tn = 0
fp = 0
fn = 0
'''
for name in names:
    test_path = "../test/" + name + ".jpg"
    for id in range(len(names)):
        result = facial_verification(id, test_path)
        if name == names[id] and result == "True":
            tp +=1
        elif name == names[id] and result == "False":
            fn += 1
        elif name != names[id] and result == "False":
            tn += 1
        else:
            fp += 1

print("äººè„¸è®¤è¯çš„è€ƒå¯Ÿç»“æœ:")
print("ç²¾åº¦:", tp/(tp+fp))
print("å›å½’ç‡:", tp/(tp+fn))
print("ç‰¹å¼‚æ€§:", tn/(tn+fp))
print("F1å€¼:", 2*tp/(2*tp+fp+fn))
'''
</code></pre></div></div>

:ET